{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff2f0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import allel\n",
    "import statistics as stat\n",
    "import statsmodels.stats.multitest as stats\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b212d64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the perl script \"fst-sliding.pl\" of the suite popoolation2 using the command:\n",
    "#./fst-sliding.pl --input sync_Dlabrax.txt --output sync_Dlabrax.fst --min-count 1 \n",
    "# --min-coverage 1 --max-coverage 100000 --window-size=1 --step-size=1 \n",
    "# --pool-size=12:23:25:25:25:25:25:25:25:25:25:25:25:25:25:25:25:25:25:25:25:11:12:25\n",
    "# window-size=1 and step-size=1 are to calculate the fst for every SNP\n",
    "sync_Dlabrax_fst = pd.read_csv(r\"C:\\Users\\arist\\Downloads\\sync_Dlabrax_LG10_popoolation.fst\", sep=\"\\t\", header=None)\n",
    "sync_Dlabrax_fst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98739500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# focus on fst differences between the farmed and the wild populations\n",
    "# pops1-10 are farmed; pops10-20 are wild\n",
    "# select cols 16-23, 38-45, 59-66, 79-86, 98-105, 116-123, 133-140, 149-156, 164-171, \n",
    "# 178-185, 191-198, 203-210\n",
    "indices = [16, 17, 18, 19, 20, 21, 22, 23,\n",
    "           34, 35, 36, 37, 38, 39, 40, 41,\n",
    "           51, 52, 53, 54, 55, 56, 57, 58,\n",
    "           67, 68, 69, 70, 71, 72, 73, 74,\n",
    "           82, 83, 84, 85, 86, 87, 88, 89,\n",
    "           96, 97, 98, 99, 100, 101, 102, 103,\n",
    "           109, 110, 111, 112, 113, 114, 115, 116,\n",
    "           121, 122,123, 124, 125, 126, 127, 128,\n",
    "           132, 133, 134, 135, 136, 137, 138 ,139,\n",
    "           142, 143, 144, 145, 146, 147, 148, 149,\n",
    "           151, 152, 153, 154, 155, 156, 157, 158,\n",
    "           159, 160, 161, 162, 163, 164, 165, 166]\n",
    "\n",
    "\n",
    "sync_Dlabrax_fst_filtered = sync_Dlabrax_fst.iloc[:, indices]\n",
    "sync_Dlabrax_fst_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7f933c",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_FST_perSNP_Dlabrax = []\n",
    "\n",
    "for row in range(len(sync_Dlabrax_fst_filtered)):\n",
    "    if row%10000 == 0:\n",
    "        print(row, end=\" \")\n",
    "    avg_FST_perSNP_perComparison = []\n",
    "    for element in range(len(list(sync_Dlabrax_fst_filtered.iloc[row,:]))):\n",
    "        num_ = float(list(sync_Dlabrax_fst_filtered.iloc[row,:])[element].split(\"=\")[1])\n",
    "        avg_FST_perSNP_perComparison.append(num_)\n",
    "    avg_FST_perSNP_Dlabrax.append(stat.mean(avg_FST_perSNP_perComparison))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de579d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the rolling average of Fst over 500 SNPs\n",
    "sync_Dlabrax_fst_df = pd.DataFrame(avg_FST_perSNP_Dlabrax, columns=[\"Fst\"])\n",
    "sync_Dlabrax_fst_df['index1'] = sync_Dlabrax_fst_df.index\n",
    "sync_Dlabrax_fst_df[\"500rollingAVG\"] = sync_Dlabrax_fst_df[\"Fst\"].rolling(window=500).mean()\n",
    "sync_Dlabrax_fst_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9be6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = sync_Dlabrax_fst[1]\n",
    "\n",
    "sync_Dlabrax_fst_df['pos'] = pos\n",
    "sync_Dlabrax_fst_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8816af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the rolling average Fst\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.plot(sync_Dlabrax_fst_df[\"500rollingAVG\"], linestyle='dashed', color = 'tab:green')\n",
    "# plt.axvline(x = 150396, color = 'r')\n",
    "# plt.axvline(x = 150397, color = 'r')\n",
    "plt.title(\"Fst rolling average over 5000 SNPs\")\n",
    "plt.xlabel('#bin') \n",
    "plt.ylabel('Fst rolling average')\n",
    "plt.show()\n",
    "# INTERESTING FINDING: which GENES are around those two peaks????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347aad51",
   "metadata": {},
   "outputs": [],
   "source": [
    "sync_Dlabrax_fst_df.to_csv(r\"C:\\Users\\arist\\Downloads\\LG10_Dlabrax_popoolation.csv\", header=True, index=False, sep=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef169e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test whether any differences in allele frequencies are statistically significant\n",
    "# using the script \"fisher-test.pl\" of popoolation\n",
    "# USAGE for Dlabrax: ./fisher-test.pl --input sync_Dlabrax.txt --output sync_Dlabrax.fet \n",
    "# --min-count 1 --min-coverage 1 --max-coverage 10000\n",
    "sync_Dlabrax_fet = pd.read_csv(\"./popoolation2_1201/sync_Dlabrax.fet\", sep=\"\\t\", header=None, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd09d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# focus on fst differences between the farmed and the wild populations\n",
    "# pops1-12 are farmed; pops13-20 are wild\n",
    "# select cols select cols 16-23, 38-45, 59-66, 79-86, 98-105, 116-123, 133-140, 149-156, 164-171, \n",
    "# 178-185, 191-198, 203-210\n",
    "indices = [16, 17, 18, 19, 20, 21, 22, 23,\n",
    "           38, 39, 40, 41, 42, 43, 44, 45,\n",
    "           59, 60, 61, 62, 63, 64, 65, 66,\n",
    "           79, 80, 81, 82, 83, 84, 85, 86,\n",
    "           98, 99, 100, 101, 102, 103, 104, 105,\n",
    "           116, 117, 118, 119, 120, 121, 122, 123,\n",
    "           133, 134, 135, 136, 137, 138, 139, 140,\n",
    "           149, 150, 151, 152, 153, 154, 155, 156,\n",
    "           164, 165, 166, 167, 168, 169, 170, 171,\n",
    "           178, 179, 180, 181, 182, 183, 184, 185, \n",
    "           191, 192, 193, 194, 195, 196, 197, 198,\n",
    "           203, 204, 205, 206, 207, 208, 209, 210]\n",
    "sync_Dlabrax_fet_filtered = sync_Dlabrax_fet.iloc[:, indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac676702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if a population is below \"--min-count 1\" and/or \"--min-coverage 1\" at the perl script above\n",
    "# then \"na\" is returned. To accomodate these few cases, \n",
    "# we drop those cases from the filtered file\n",
    "# and use \"pass\" to not include them to the generated list\n",
    "# IMPORTANT: SIGNIFICANCE IS REPORTED AS -LOG(P-VALUE)!!!!\n",
    "# -LOG(0.01) = 2 (thus we search for values > 2)\n",
    "# The loop below calculates the PERCENTAGE of pairwise comparisons per SNP that have -LOG(P-val) > 2 (p < 1%)\n",
    "\n",
    "PERCENT_SIGN_FET_perSNP_Dlabrax = []\n",
    "dropped_indices = []\n",
    "\n",
    "for row in range(len(sync_Dlabrax_fet_filtered)):\n",
    "    if row%10000 == 0:\n",
    "        print(row, end=\" \")\n",
    "    count_sign_FET = 0\n",
    "    try:\n",
    "        for element in range(len(list(sync_Dlabrax_fet_filtered.iloc[row,:]))):\n",
    "            num_ = round(float(sync_Dlabrax_fet_filtered.iloc[row,element].split(\"=\")[1]), 3)\n",
    "            if num_ > 1.3:  # 0.05 significance\n",
    "                count_sign_FET += 1\n",
    "        PERCENT_SIGN_FET_perSNP_Dlabrax.append(round(count_sign_FET/142, 3)*100)  # 142=tot pairwise comps\n",
    "    except ValueError:\n",
    "        dropped_indices.append(row)\n",
    "        pass\n",
    "\n",
    "# =======================================================================================================\n",
    "# another variation of the above \"for\" loop, which estimates the AVERAGE -LOG(P-val) per row\n",
    "\n",
    "# AVERAGE_FET_per_SNP_Dlabrax = []\n",
    "# dropped_indices = []\n",
    "\n",
    "# for row in range(len(sync_Dlabrax_fet_filtered)):\n",
    "#     FET_values_per_SNP = []\n",
    "#     if row%10000 == 0:\n",
    "#         print(row, end=\" \")\n",
    "#     try:\n",
    "#         for element in range(len(list(sync_Dlabrax_fet_filtered.iloc[row,:]))):\n",
    "#             num_ = round(float(sync_Dlabrax_fet_filtered.iloc[row,element].split(\"=\")[1]), 3)\n",
    "#             FET_values_per_SNP.append(num_)\n",
    "#         row_mean = stat.mean(FET_values_per_SNP)\n",
    "#         AVERAGE_FET_per_SNP_Dlabrax.append(row_mean)\n",
    "#     except ValueError:\n",
    "#         dropped_indices.append(row)\n",
    "#         pass\n",
    "# ======================================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d7aa42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 81 cases with \"na\" that will be dropped\n",
    "len(dropped_indices)\n",
    "sync_Dlabrax_fet_filtered = sync_Dlabrax_fet_filtered.drop(index = dropped_indices)\n",
    "\n",
    "# make certain to round the resulted averages to 3 decimals\n",
    "PERCENT_SIGN_FET_perSNP_Dlabrax = [round(x, 3) for x in PERCENT_SIGN_FET_perSNP_Dlabrax]\n",
    "\n",
    "# add averages as new column to the \"sync_Dlabrax_fet_filtered\" df\n",
    "sync_Dlabrax_fet_filtered[\"PERCENT_SIGN\"] = PERCENT_SIGN_FET_perSNP_Dlabrax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5dd3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================================================================================\n",
    "# same as just above, but for the variation with the AVERAGE -LOG(P-val) per row\n",
    "# 81 cases with \"na\" that will be dropped\n",
    "len(dropped_indices)\n",
    "sync_Dlabrax_fet_filtered = sync_Dlabrax_fet_filtered.drop(index = dropped_indices)\n",
    "\n",
    "# make certain to round the resulted averages to 3 decimals\n",
    "AVERAGE_FET_per_SNP_Dlabrax = [round(x, 3) for x in AVERAGE_FET_per_SNP_Dlabrax]\n",
    "\n",
    "# add averages as new column to the \"sync_Dlabrax_fet_filtered\" df\n",
    "sync_Dlabrax_fet_filtered[\"AVERAGE_SIGN\"] = AVERAGE_FET_per_SNP_Dlabrax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d9c098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the rolling average\n",
    "sync_Dlabrax_fet_filtered[\"5000rollingAVG-PERCENT\"] = sync_Dlabrax_fet_filtered[\"PERCENT_SIGN\"].rolling(window=5000).mean()\n",
    "\n",
    "# plot the rolling average Fst\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.plot(sync_Dlabrax_fet_filtered[\"5000rollingAVG-PERCENT\"], linestyle='dashed', color = 'tab:green')\n",
    "plt.axvline(x = 150396, color = 'r')\n",
    "plt.axvline(x = 150397, color = 'r')\n",
    "plt.title(\"Percent of pairwise comparisons with -LOG(P-val) > 2 (p < 1%)\")\n",
    "plt.xlabel('#bin') \n",
    "plt.ylabel('Percent')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329a21c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CORRECT FOR MULTIPLE TESTING WITH THE BH METHOD\n",
    "\n",
    "# the \"for\" loop of above, which estimates the AVERAGE -LOG(P-val) per row\n",
    "# modified to correct for multiple test\n",
    "\n",
    "AVERAGE_FET_per_SNP_Dlabrax_BHcor = []\n",
    "dropped_indices = []\n",
    "\n",
    "for row in range(len(sync_Dlabrax_fet_filtered)):\n",
    "    FET_values_per_SNP = []\n",
    "    if row%10000 == 0:\n",
    "        print(row, end=\" \")\n",
    "    try:\n",
    "        for element in range(len(list(sync_Dlabrax_fet_filtered.iloc[row,:]))):\n",
    "            num_ = round(float(sync_Dlabrax_fet_filtered.iloc[row,element].split(\"=\")[1]), 3)\n",
    "            num_ = 10**(-num_)  # convert num_ from log10(p-value) to p-value\n",
    "            FET_values_per_SNP.append(num_)\n",
    "        # run the multiple correction\n",
    "        FET_values_per_SNP_cor = stats.multipletests(FET_values_per_SNP, alpha=0.05, method='fdr_bh', is_sorted=False, returnsorted=False)[1]\n",
    "        # convert the corrected values back to log10\n",
    "        FET_values_per_SNP_cor = [-math.log10(x) for x in list(FET_values_per_SNP_cor)]\n",
    "        row_mean_cor = stat.mean(FET_values_per_SNP_cor)\n",
    "        AVERAGE_FET_per_SNP_Dlabrax_BHcor.append(row_mean_cor)\n",
    "    except ValueError:\n",
    "        dropped_indices.append(row)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a90132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================================================================================\n",
    "# same as just above, but for the variation with the AVERAGE -LOG(P-val) per row\n",
    "# 81 cases with \"na\" that will be dropped\n",
    "len(dropped_indices)\n",
    "sync_Dlabrax_fet_filtered = sync_Dlabrax_fet_filtered.drop(index = dropped_indices)\n",
    "\n",
    "# make certain to round the resulted averages to 3 decimals\n",
    "AVERAGE_FET_per_SNP_Dlabrax_BHcor = [round(x, 3) for x in AVERAGE_FET_per_SNP_Dlabrax_BHcor]\n",
    "\n",
    "# add averages as new column to the \"sync_Dlabrax_fet_filtered\" df\n",
    "sync_Dlabrax_fet_filtered[\"AVERAGE_SIGN_BHcor\"] = AVERAGE_FET_per_SNP_Dlabrax_BHcor\n",
    "# ======================================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ceb9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same as above, but for the AVERAGE -LOG(P-val) per row\n",
    "# calculate the rolling average\n",
    "sync_Dlabrax_fet_filtered[\"500rollingAVG_BHcor\"] = sync_Dlabrax_fet_filtered[\"AVERAGE_SIGN_BHcor\"].rolling(window=500).mean()\n",
    "\n",
    "# plot the rolling average Fst\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.plot(sync_Dlabrax_fet_filtered[\"5000rollingAVG_BHcor\"], linestyle='dashed', color = 'tab:green')\n",
    "plt.axvline(x = 150396, color = 'r')\n",
    "plt.axvline(x = 150397, color = 'r')\n",
    "plt.axhline(y = 1.3, color = 'r')\n",
    "plt.title(\"Rolling averaged significance as -LOG(P-val)\")\n",
    "plt.xlabel('#bin') \n",
    "plt.ylabel('-LOG(P-val)_BHcor')\n",
    "plt.show()\n",
    "# Maybe too conservative that rolling average of 5000?\n",
    "# What I would do is focus on individual points that stayed significant - see cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4964fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# focus on individual points with fdr-corrected data\n",
    "# notice that index \"100426\" (first peak) has -log(p-val) = 5.834 ==> pval = 1.47e-06\n",
    "# also index \"165381\" (second peak) has -log(p-val) = 5.407 ==> pval = 3.91e-06\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "sync_Dlabrax_fet_filtered[sync_Dlabrax_fet_filtered[\"AVERAGE_SIGN_BHcor\"] > 1.3].sort_values(by=['AVERAGE_SIGN_BHcor'], ascending=False).head(500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
